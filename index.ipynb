{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install segmentation_models_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, torch, cv2, numpy as np, albumentations as A\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import segmentation_models_pytorch as smp\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from segmentation_models_pytorch.losses import JaccardLoss, DiceLoss\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    SegformerForSemanticSegmentation,\n",
    "    Mask2FormerForUniversalSegmentation,\n",
    "    Mask2FormerImageProcessor\n",
    ")\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSegmentationDataset(Dataset):\n",
    "    def __init__(self, root, transformations=None):\n",
    "        self.im_paths = sorted(glob(f'{root}/*/images/*.jpg'))\n",
    "        self.gt_paths = sorted(glob(f'{root}/*/masks/*.png'))\n",
    "        self.transformations = transformations\n",
    "        self.n_cls = 5\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.im_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        im, gt = self.get_im_gt(self.im_paths[idx], self.gt_paths[idx])\n",
    "        if self.transformations:\n",
    "            im, gt = self.apply_transformations(im, gt)\n",
    "        return im, gt\n",
    "    \n",
    "    def get_im_gt(self, im_path, gt_path):\n",
    "        return self.read_im(im_path), self.read_im(gt_path)\n",
    "    \n",
    "    def read_im(self, path):\n",
    "        return cv2.cvtColor(cv2.imread(path, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    def apply_transformations(self, im, gt):\n",
    "        transformed = self.transformations(image=im, mask=gt)\n",
    "        return transformed['image'], transformed['mask'], im, gt\n",
    "\n",
    "def collate_fn(batch, image_processor):\n",
    "    inputs = list(zip(*batch))\n",
    "    images = inputs[0]\n",
    "    segmentation_maps = inputs[1]\n",
    "\n",
    "    batch = image_processor(\n",
    "        images,\n",
    "        segmentation_maps=segmentation_maps,\n",
    "        return_tensors='pt',\n",
    "        do_resize=False,\n",
    "        do_rescale=False,\n",
    "        do_normalize=False\n",
    "    )\n",
    "\n",
    "    batch['orig_image'] = inputs[2]\n",
    "    batch['orig_mask'] = inputs[3]\n",
    "    return batch\n",
    "\n",
    "def get_dls(root, transformations, bs, processor=None, split=[0.9,0.05,0.05]):\n",
    "    assert sum(split) == 1., 'Sum of the split must be exactly 1'\n",
    "    ds = CustomSegmentationDataset(root=root, transformations=transformations)\n",
    "    n_cls = ds.n_cls\n",
    "    tr_len = int(len(ds) * split[0])\n",
    "    val_len = int(len(ds) * split[1])\n",
    "    test_len = len(ds) - (tr_len + val_len)\n",
    "    tr_ds, val_ds, test_ds = torch.utils.data.random_split(\n",
    "        ds,\n",
    "        [tr_len, val_len, test_len]\n",
    "    )\n",
    "    print(len(tr_ds))\n",
    "    print(len(val_ds))\n",
    "    print(len(test_ds))\n",
    "    collate_func = None\n",
    "    if processor:\n",
    "        collate_func = partial(collate_fn, image_processor=processor)\n",
    "    # Get dataloaders\n",
    "    tr_dl  = DataLoader(\n",
    "        dataset=tr_ds,\n",
    "        batch_size=bs,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_func\n",
    "    )\n",
    "    val_dl = DataLoader(\n",
    "        dataset = val_ds,\n",
    "        batch_size = bs,\n",
    "        shuffle = False,\n",
    "        collate_fn=collate_func\n",
    "    )\n",
    "    test_dl = DataLoader(\n",
    "        dataset = test_ds,\n",
    "        batch_size = 1,\n",
    "        shuffle = False,\n",
    "        collate_fn=collate_func\n",
    "    )\n",
    "    return tr_dl, val_dl, test_dl, n_cls\n",
    "    \n",
    "root = '/kaggle/input/semantic-segmentation-of-aerial-imagery/Semantic segmentation dataset'\n",
    "mean, std, im_h, im_w = [0.485, 0.456, 0.406], [0.229,0.224,0.225], 256, 256\n",
    "trans = A.Compose([\n",
    "    A.Resize(im_h, im_w),\n",
    "#     A.augmentations.transforms.Normalize(mean=mean, std=std),\n",
    "#     ToTensorV2(transpose_mask=True)\n",
    "])\n",
    "tr_dl, val_dl, test_dl, n_cls = get_dls(\n",
    "    root=root,\n",
    "    transformations=trans,\n",
    "    bs=4\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics():\n",
    "    def __init__(self, pred, gt, loss_fn, eps=1e-10, n_cls=2):\n",
    "        self.pred, self.gt = torch.argmax(F.softmax(pred, dim=1), dim=1), gt\n",
    "        self.loss_fn, self.eps, self.n_cls, self.pred_ = loss_fn, eps, n_cls, pred\n",
    "    \n",
    "    def to_contiguous(self, inp):\n",
    "        return inp.contiguous().view(-1)\n",
    "    \n",
    "    def PA(self):\n",
    "        with torch.no_grad():\n",
    "            match = torch.eq(self.pred, self.gt).int()\n",
    "        return float(match.sum()) / float(match.numel())\n",
    "    \n",
    "    def mIoU(self):\n",
    "        with torch.no_grad():\n",
    "            self.gt = torch.argmax(self.gt, dim=1)\n",
    "            pred, gt = self.to_contiguous(self.pred), self.to_contiguous(self.gt)\n",
    "            iou_per_class = []\n",
    "            for c in range(self.n_cls):\n",
    "                match_pred = pred == c\n",
    "                match_gt = gt == c\n",
    "                if match_gt.long().sum().item() == 0:\n",
    "                    iou_per_class.append(np.nan)\n",
    "                else:\n",
    "                    intersect = torch.logical_and(match_pred, match_gt).sum().float().item()\n",
    "                    union = torch.logical_or(match_pred, match_gt).sum().float().item()\n",
    "                    iou = (intersect + self.eps) / (union + self.eps)\n",
    "                    iou_per_class.append(iou)\n",
    "            return np.nanmean(iou_per_class)\n",
    "    \n",
    "    def loss(self):\n",
    "        return self.loss_fn(self.pred_, torch.argmax(self.gt, dim=1))\n",
    "    \n",
    "def tic_toc(start_time=None):\n",
    "    return time.time() if start_time == None else time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model_name,\n",
    "    model,\n",
    "    tr_dl,\n",
    "    val_dl,\n",
    "    loss_fn,\n",
    "    opt,\n",
    "    device,\n",
    "    epochs,\n",
    "    save_prefix,\n",
    "    save_path='saved_models',\n",
    "    is_huggingface_model=False\n",
    "):\n",
    "    tr_loss, tr_pa, tr_iou = [],[],[]\n",
    "    val_loss, val_pa, val_iou = [],[],[]\n",
    "    tr_len, val_len = len(tr_dl), len(val_dl)\n",
    "    best_loss, decrease, not_improve, early_stop_threshold = np.inf, 1, 0, 7\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    model.to(device)\n",
    "    train_start = tic_toc()\n",
    "    print('Start training process...')\n",
    "    for epoch in range(1, epochs+1):\n",
    "        tic = tic_toc()\n",
    "        tr_loss_, tr_iou_, tr_pa_ = 0,0,0\n",
    "        model.train()\n",
    "        print(f'Epoch {epoch} train process is started...')\n",
    "        for idx, batch in enumerate(tqdm(tr_dl)):\n",
    "            ims, gts = batch\n",
    "            ims, gts = ims.to(device), gts.to(device)\n",
    "            if model_name == \"segformer\":\n",
    "                preds = model(ims)\n",
    "                preds = preds.logits\n",
    "                preds = nn.functional.interpolate(\n",
    "                    preds,\n",
    "                    size=ims.shape[-2:],\n",
    "                    mode=\"bilinear\",\n",
    "                    align_corners=False\n",
    "                )\n",
    "            elif model_name == \"mask2former\":\n",
    "                pass\n",
    "            else:\n",
    "                preds = model(ims)\n",
    "\n",
    "            met = Metrics(preds, gts, loss_fn, n_cls=n_cls)\n",
    "            loss_ = met.loss()\n",
    "#             print(\"loss\", loss_)\n",
    "            tr_iou_ += met.mIoU()\n",
    "            tr_pa_ += met.PA()\n",
    "            tr_loss_ += loss_.item()\n",
    "            loss_.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        print(f\"Epoch {epoch} validation process is started...\")\n",
    "        model.eval()\n",
    "        val_loss_, val_iou_, val_pa_ = 0,0,0\n",
    "        with torch.no_grad():\n",
    "            for idx, batch in enumerate(tqdm(val_dl)):\n",
    "                ims, gts = batch\n",
    "                ims, gts = ims.to(device), gts.to(device)\n",
    "                if model_name == \"segformer\":\n",
    "                    preds = model(ims)\n",
    "                    preds = preds.logits\n",
    "                    preds = nn.functional.interpolate(\n",
    "                        preds,\n",
    "                        size=ims.shape[-2:],\n",
    "                        mode=\"bilinear\",\n",
    "                        align_corners=False\n",
    "                    )\n",
    "                else:\n",
    "                    preds = model(ims)\n",
    "                met = Metrics(preds, gts, loss_fn, n_cls=n_cls)\n",
    "                val_loss_ += met.loss().item()\n",
    "                val_iou_ += met.mIoU()\n",
    "                val_pa_ += met.PA()\n",
    "        \n",
    "        print(f'Epoch {epoch} train process is completed')\n",
    "        tr_loss_ /= tr_len\n",
    "        tr_iou_ /= tr_len\n",
    "        tr_pa_ /= tr_len\n",
    "        \n",
    "        val_loss_ /= val_len\n",
    "        val_iou_ /= val_len\n",
    "        val_pa_ /= val_len\n",
    "        \n",
    "        print(\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "        print(f\"\\nEpoch {epoch} train process results: \\n\")\n",
    "        print(f\"Train Time         -> {tic_toc(tic):.3f} secs\")\n",
    "        print(f\"Train Loss         -> {tr_loss_:.3f}\")\n",
    "        print(f\"Train PA           -> {tr_pa_:.3f}\")\n",
    "        print(f\"Train IoU          -> {tr_iou_:.3f}\")\n",
    "        print(f\"Validation Loss    -> {val_loss_:.3f}\")\n",
    "        print(f\"Validation PA      -> {val_pa_:.3f}\")\n",
    "        print(f\"Validation IoU     -> {val_iou_:.3f}\\n\")\n",
    "        \n",
    "        tr_loss.append(tr_loss_)\n",
    "        tr_iou.append(tr_iou_)\n",
    "        tr_pa.append(tr_pa_)\n",
    "\n",
    "        val_loss.append(val_loss_)\n",
    "        val_iou.append(val_iou_)\n",
    "        val_pa.append(val_pa_)\n",
    "        \n",
    "        if best_loss > (val_loss_):\n",
    "            print(f\"Loss decreased from {best_loss:.3f} to {val_loss_:.3f}!\")\n",
    "            best_loss = val_loss_\n",
    "            decrease += 1\n",
    "#             not_improve = 0\n",
    "            if decrease % 2 == 0:\n",
    "                print(\"Saving the model with the best loss value...\")\n",
    "                torch.save(model, f\"{save_path}/{save_prefix}_best_model.pt\")\n",
    "            \n",
    "        if val_loss_ > best_loss:\n",
    "\n",
    "            not_improve += 1\n",
    "            best_loss = val_loss_\n",
    "            print(f\"Loss did not decrease for {not_improve} epoch(s)!\")\n",
    "            if not_improve == early_stop_threshold:\n",
    "                print(f\"Stopping training process becuase loss value did not decrease for {early_stop_threshold} epochs!\")\n",
    "                break\n",
    "        print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n",
    "            \n",
    "    print(f\"Train process is completed in {(tic_toc(train_start)) / 60:.3f} minutes.\")\n",
    "    \n",
    "    return {\"tr_loss\": tr_loss, \"tr_iou\": tr_iou, \"tr_pa\": tr_pa,\n",
    "            \"val_loss\": val_loss, \"val_iou\": val_iou, \"val_pa\" : val_pa}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor\n",
    "# from transformers import Mask2FormerForUniversalSegmentation, Mask2FormerImageProcessor\n",
    "# processor = SegformerImageProcessor()\n",
    "processor = Mask2FormerImageProcessor()\n",
    "tr_dl, val_dl, test_dl, n_cls = get_dls(\n",
    "    root=root,\n",
    "    transformations=trans,\n",
    "    bs=4,\n",
    "    processor=processor\n",
    ")\n",
    "batch = next(iter(tr_dl))\n",
    "imgs, labels = batch\n",
    "print(imgs.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "# pixel_values = processor.preprocess(imgs, labels, return_tensors='pt').to('cuda')\n",
    "model = Mask2FormerForUniversalSegmentation.from_pretrained(\n",
    "    'facebook/mask2former-swin-tiny-ade-semantic',\n",
    "    num_labels=n_cls,\n",
    "    ignore_mismatched_sizes=True\n",
    ").to('cuda')\n",
    "outputs = model(**pixel_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_segmetation = processor.post_process_semantic_segmentation(\n",
    "    outputs,\n",
    "    target_sizes=[(256,256)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"segformer\"\n",
    "if model_name == \"deeplab3plus\":\n",
    "    model = smp.DeepLabV3Plus(classes=n_cls)\n",
    "elif model_name == \"unet\":\n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"timm-efficientnet-b8\",\n",
    "        encoder_weights='imagenet',\n",
    "        in_channels=3,\n",
    "        classes=n_cls,\n",
    "    )\n",
    "elif model_name == \"segformer\":\n",
    "    model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "        'nvidia/mit-b5',\n",
    "        num_labels=n_cls,\n",
    "    )\n",
    "elif model_name == \"mask2former\":\n",
    "    model = Mask2FormerForUniversalSegmentation.from_pretrained(\n",
    "        'facebook/mask2former-swin-tiny-ade-semantic',\n",
    "        num_labels=n_cls,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "else:\n",
    "    model = smp.DeepLabV3Plus(classes=n_cls)\n",
    "\n",
    "# loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss_fn = JaccardLoss(mode='multiclass')\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-4)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "history = train(\n",
    "    model_name=model_name,\n",
    "    model=model,\n",
    "    tr_dl=tr_dl,\n",
    "    val_dl=val_dl,\n",
    "    loss_fn=loss_fn,\n",
    "    opt=optimizer,\n",
    "    device=device,\n",
    "    epochs=50,\n",
    "    save_prefix=\"aerial\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plot():\n",
    "    \n",
    "    def __init__(self, res):\n",
    "        \n",
    "        self.res = res\n",
    "        \n",
    "        self.visualize(metric1 = \"tr_iou\", metric2 = \"val_iou\", label1 = \"Train IoU\", \n",
    "                  label2 = \"Validation IoU\", title = \"Mean Intersection Over Union Learning Curve\", ylabel = \"mIoU Score\")\n",
    "    \n",
    "        self.visualize(metric1 = \"tr_pa\", metric2 = \"val_pa\", label1 = \"Train PA\", \n",
    "                  label2 = \"Validation PA\", title = \"Pixel Accuracy Learning Curve\", ylabel = \"PA Score\")\n",
    "        \n",
    "        self.visualize(metric1 = \"tr_loss\", metric2 = \"val_loss\", label1 = \"Train Loss\", \n",
    "                  label2 = \"Validation Loss\", title = \"Loss Learning Curve\", ylabel = \"Loss Value\")\n",
    "        \n",
    "        \n",
    "    def plot(self, metric, label): plt.plot(self.res[metric], label = label)\n",
    "    \n",
    "    def decorate(self, ylabel, title): plt.title(title); plt.xlabel(\"Epochs\"); plt.ylabel(ylabel); plt.legend(); plt.show()\n",
    "    \n",
    "    def visualize(self, metric1, metric2, label1, label2, title, ylabel):\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        self.plot(metric1, label1); self.plot(metric2, label2)\n",
    "        self.decorate(ylabel, title)                \n",
    "        \n",
    "Plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision import transforms as tfs\n",
    "\n",
    "def tn_2_np(t): \n",
    "    invTrans = tfs.Compose([ tfs.Normalize(mean = [ 0., 0., 0. ], std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
    "                                tfs.Normalize(mean = [ -0.485, -0.456, -0.406 ], std = [ 1., 1., 1. ]) ])\n",
    "    \n",
    "    rgb = True if len(t) == 3 else False\n",
    "    \n",
    "    return (invTrans(t) * 255).detach().cpu().permute(1,2,0).numpy().astype(np.uint8) if rgb else (t*255).detach().cpu().numpy().astype(np.uint8)\n",
    "\n",
    "def plot(rows, cols, count, im, gt = None, title = \"Original Image\"):\n",
    "    plt.subplot(rows, cols, count)\n",
    "    plt.imshow(tn_2_np(im.squeeze(0).float())) if gt else plt.imshow(tn_2_np(im.squeeze(0)))\n",
    "    plt.axis(\"off\"); plt.title(title)\n",
    "    return count + 1\n",
    "\n",
    "def visualize(ds, n_ims):\n",
    "    \n",
    "    plt.figure(figsize = (25, 20))\n",
    "    rows = n_ims // 4; cols = n_ims // rows\n",
    "    count = 1\n",
    "    indices = [random.randint(0, len(ds) - 1) for _ in range(n_ims)]\n",
    "    \n",
    "    for idx, index in enumerate(indices):\n",
    "        \n",
    "        if count == n_ims + 1: break\n",
    "        im, gt = ds[index]\n",
    "        \n",
    "        # First Plot\n",
    "        count = plot(rows, cols, count, im = im)\n",
    "        \n",
    "        # Second Plot\n",
    "        count = plot(rows, cols, count, im = gt, gt = True)\n",
    "        \n",
    "visualize(tr_dl.dataset, n_ims = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(dl, model_name, model, device, n_ims = 15):\n",
    "    \n",
    "    cols = n_ims // 3; rows = n_ims // cols\n",
    "    \n",
    "    count = 1\n",
    "    ims, gts, preds = [], [], []\n",
    "    for idx, data in enumerate(dl):\n",
    "        im, gt = data\n",
    "\n",
    "        # Get predicted mask\n",
    "        with torch.no_grad():\n",
    "#             pred = torch.argmax(model(im.to(device)), dim = 1)\n",
    "            if model_name == \"segformer\":\n",
    "#                 print(pred.shape)\n",
    "                pred = model(im.to(device)).logits\n",
    "                pred = nn.functional.interpolate(\n",
    "                    pred,\n",
    "                    size=im.shape[-2:],\n",
    "                    mode=\"bilinear\",\n",
    "                    align_corners=False\n",
    "                )\n",
    "                pred = torch.argmax(pred, dim = 1)\n",
    "            else:\n",
    "                pred = torch.argmax(model(im.to(device)), dim = 1)\n",
    "        ims.append(im);\n",
    "        gts.append(gt);\n",
    "        preds.append(pred)\n",
    "#         print(pred.unique())\n",
    "        \n",
    "    plt.figure(figsize = (25, 20))\n",
    "    for idx, (im, gt, pred) in enumerate(zip(ims, gts, preds)):\n",
    "        if idx == cols: break\n",
    "        \n",
    "        # First plot\n",
    "        count = plot(cols, rows, count, im)\n",
    "\n",
    "        # Second plot\n",
    "        count = plot(cols, rows, count, im = gt, gt = True, title = \"Ground Truth\")\n",
    "\n",
    "        # Third plot\n",
    "        count = plot(cols, rows, count, im = pred, title = \"Predicted Mask\")\n",
    "\n",
    "model = torch.load(\"/kaggle/working/saved_models/aerial_best_model.pt\")\n",
    "inference(\n",
    "    test_dl,\n",
    "    model_name=model_name,\n",
    "    model=model,\n",
    "    device=device,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
